import streamlit as st
import time
from rag_system import get_retrieval_chain

# --- Main Application ---
st.set_page_config(
    page_title="Healthwise RAG",
    page_icon="➕",
    layout="wide",
)

st.title("➕ Healthwise RAG")

# Add a description or instructions
st.markdown(
    """
    **Ask a question about chronic diseases or public health.**
    
    _This system uses a Retrieval-Augmented Generation (RAG) model to find relevant information from trusted sources and provide a grounded, accurate answer._
    """
)

# --- Initialize Session State ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "retrieval_chain" not in st.session_state:
    st.session_state.retrieval_chain = None

# --- Setup and Error Handling ---
with st.spinner("Setting up the RAG system... This may take a moment."):
    try:
        if st.session_state.retrieval_chain is None:
            st.session_state.retrieval_chain = get_retrieval_chain()
        st.success("System ready!")
    except Exception as e:
        st.error(
            f"An error occurred during setup: {e}"
        )
        st.warning(
            "Please check your environment variables, especially your Hugging Face API token, and ensure you have an active internet connection."
        )
        st.stop()

# --- Chat History Display ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- Chat Input Handler ---
if prompt := st.chat_input("Ask a question..."):
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        # Use a Streamlit-friendly streaming method
        response_generator = st.session_state.retrieval_chain.stream({"input": prompt})

        for chunk in response_generator:
            if isinstance(chunk, str):
                full_response += chunk
            elif isinstance(chunk, dict) and "answer" in chunk:
                full_response += chunk["answer"]

            time.sleep(0.01) # Simulate typing for better user experience
            message_placeholder.markdown(full_response + "▌")
        
        message_placeholder.markdown(full_response)
        
    st.session_state.messages.append({"role": "assistant", "content": full_response})
